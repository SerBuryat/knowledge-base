- [ ] `publishOn` method for assigning job for some `ThreadPool`
- [ ] `WebClient` has "*event loop* style"
- [ ] WebFlux and Reactor concurrency models
- [ ] **==IMHO==** reactive model: 
- request in -> netty-thread send it to event queue -> netty-thread returns to netty's thread pool 
- *event loop* assign handler(worker-thread) for event -> worker faced IO bound task -> worker sent to queue -> worker returns to worker's thread pool
- IO bound sent "ready for process" event (data is coming from DB, REST API etc.)
- *event loop* assign handler(worker-thread) for event -> worker sent response out -> worker returns to worker's thread pool
- [ ] - reactive *event loop* register *callback* via **==platform==** (==*is OS kernel level API*???==), platform check completaion status and trigger worker thread (WebFlux) to continue code via callback - https://www.baeldung.com/spring-webflux-concurrency
- [ ] - reactive programming models
- [ ] - **==one thread==** (usually *event loop*) **==can check (via *endless loop*) for I/O operation==** completion **==instead every thread blocked==** until it (*event-driven systems* based on this approach)
- [ ] - *event-driven systems* divided into parts (*event handlers*) communicated via *events* and *event-queue* (they move events to queue and single thread infinitly check this queue and run event handlers???)
- [ ] - reactive vs *event-driven system* (reactive based on event-driven???)
- [ ] - [Spring WebFlux threading model](https://hackernoon.com/an-intro-to-spring-webflux-threading-model)
- [ ] - [Spring WebFlux Visualized: Threading and EventLoops](https://www.stefankreidel.io/blog/spring-webflux) (well visualized via gifs)
-  The core of *reactive programming* defines, that **instead of waiting for blocking operation (I/O bound) to finish, threads do other things in the meantime and pick up the response after the operation completed**
- *reactive programming* is first and **foremost centered around non-blocking**
- parts of a request can be handled by multiple threads (1st - accept request, 2nd - process, 3rd - complete etc.)
- requests are handled by `EventLoops`. **`EventLoops` are basically just threads** with the addition that **they have to run at all** time (cpu bound jobs)
- once a blocking operation is reached, **`EventLoops` do not wait around for the operation to be finished** (register *callback* which will execute when I/O finishes) but **hand over the execution context** (some 'threadlocal' data ) and are then free to process other requests
- **java NIO is core of non-blocking I/O in Spring WebFlux**
- `EventLoops` to handle many requests **only works** and scales efficiently, **if all blocking operations are implemented reactively**
- for blocking (non reactive impl ops) use `Scheduler` (`publishOn(Schedulers.boundedElastic())`) **it helps don't block `EventLoop` threads** (`Schedulers.boundedElastic()` threads are **more lightweight and intended to be used for blocking operations**)
- for heavy compute steps as the bounded-elastic threads are intended for, use `.publishOn(Schedulers.parallel())` 
- async and non-blocking I/O is two aspects to impl a parallelism
	- non-blocking I/O is I/O complition without blocking *thread* (CPU) via *DMA*/sockets/platform features
	- async is run parallel thread using several CPUs
- [ ] - [Netty brief nutshell](https://baekjungho.github.io/wiki/spring/spring-netty/) - threading model, core concepts and components(+links)
- [ ] - [Performance Comparison — Thread Pool vs. Virtual Threads (Project Loom) In Spring Boot Applications](https://dzone.com/articles/request-handling-approaches-threadpool-webflux-cor) - usefull perfomance graphics
- [ ] - There’s also an initiative to standardize the reactive streams API. The initiative is called [Reactive Streams](https://www.reactive-streams.org/). It defines a set of rules for asynchronous stream processing with non-blocking back pressure.
- [ ] - reactive programming paradigm based on decouple receive events/messages/request/signals and handling/process them in parallel or later. Reactive consists of *async* and *non-blocking* approach where *main thread* **==not blocked==** and **==async event handling==**. **Don't be confused with *non-blocking I/O*(!!!)** this is **just possibility of platform to non-blocking/async I/O processes handling** (via `epoll()`, `wepoll()` etc.)
- [ ] - *Observer pattern* It is often used for implementing distributed [event-handling](https://en.wikipedia.org/wiki/Event_handling "Event handling") systems in [event-driven software](https://en.wikipedia.org/wiki/Event-driven_programming "Event-driven programming")
- *Observer pattern*  and implementations :
	- Observer: **observable has a list of observers and notify them after some state changes**
	- *Publisher-subscriber pattern* is a decoupled variation of Observer: **publisher send a message about state changing into message queue and subscribers gonna notified and poll this message**
	- *Event Emitter/Target/Dispatcher pattern*
	- *Signals pattern*
- [ ] - [ReactiveX](https://reactivex.io/) (Rx) - language agnostic specification of reactive APIs developed by Microsoft
- [ ] - Based on Rx specification  [Reactive Streams](https://github.com/reactive-streams/reactive-streams-jvm) is provider a **standard for asynchronous stream processing** with non-blocking backpressure for Java
- [ ] -  Reactive Streams impls: 
- [RxJava](https://github.com/ReactiveX/RxJava)  developed by Netflix 
- [Project Reactor](https://github.com/reactor/reactor-core)
- Spring Web Flux based on Project Reactor
- [ ] - Flow API is Java's official support for [Reactive Streams Specification](http://www.reactive-streams.org/) (`java.util.concurrent.Flow`) 
- [ ] - Reactive Streams has [FlowAdapters](https://github.com/reactive-streams/reactive-streams-jvm/blob/master/api/src/main/java9/org/reactivestreams/FlowAdapters.java) to implement Flow API after it's introduction
- [ ] - Good *RP* [article](https://gist.github.com/staltz/868e7e9bc2a7b8c1f754) and [working Rx JS example](https://jsfiddle.net/staltz/8jFJH/48/) (sandbox)
- [ ] - *RP* is just a way to manage of async data streams **???** 
> *The main goal of Reactive Streams is to* **govern the exchange of stream data across an asynchronous boundary**
> Multiple async operations linked in a chain and managed in some way - Reactive Programming **???**

- [ ] - The [Reactor Pattern](https://www.dre.vanderbilt.edu/~schmidt/PDF/reactor-siemens.pdf) utilizes an intermediary service handler which demultiplexes requests and dispatches to the correct handler.
- [ ] - The [Observer Pattern](https://en.wikipedia.org/wiki/Observer_pattern) requires that "Observers" register with the subject, which then pushes notifications to all registered observers when an event occurs.
- [ ] - good simple [overview](https://struchkov.dev/blog/ru/overview-of-reactive-programming/) about reactive programming and reactive systems
- [ ] - Reactive Streams under-hood ([video](https://www.youtube.com/watch?v=qmuNAWKNJWs))
- [ ] - Java Reactive Streams vs Java Stream API
- [ ] - Unlike Java 8's streams, RxJava also has a [backpressure](http://reactivex.io/documentation/operators/backpressure.html) mechanism, which allows it to handle cases in which different parts of your processing pipeline operate in different threads, _at different rates_.
- [ ] - [Spring WebFlux vs Node.js performance compare](https://community.sap.com/t5/technology-blogs-by-members/spring-boot-reactive-vs-node-js-in-sap-cloud-platform-reflection-on/ba-p/13374735)
- ![[spring-webflux-vs-node-js-perfomance-compare.png]]
- 1, 5, 10, 20, 30, 40, 50 users - 1000 requests/user loop
- [ ] - Following are the core concepts of Reactive Programming (ReactiveX): 
- Observable
- Observer
- Subscribe
- Subscription
- [ ] - Observer design pattern is the building block of Reactive Programming
- [ ] - pull/push reactive model
- [ ] - backpressure (to not overwhelm Observers with Observable events)
- [ ] - Essentially Functional Programming is regarded as an important aspect of Reactive Programming
- [ ] - Functional Programming promotes immutability making concurrent programming easier
- [ ] - In Reactor, the execution model and where the execution happens is determined by the `Scheduler` that is used. A `Scheduler` has scheduling responsibilities similar to an `ExecutorService`.
- [ ] - By definition, every stream is lazy. This means that nothing is executed until you consume the stream with `subscribe()`. This possibility provided by functional programming where every function is lazy.
- [ ] - Flux and Mono are immutable. This means that an instance of any of them can not be modified at all. Calling any method on them will return a new instance of Flux or Mono. This possibility provided by functional programming where every function is immutable.
- [ ] - The 4 schedulers offered by Reactor are :
- **single**: a one worker thread scheduler
- **immediate**: a scheduler that computes the stream in the thread where the call to the method configuring it is done.
- **parallel**: a scheduler that has as many workers as your CPU has cores (or threads if supporting hyper threading). The method it uses to get the amount of workers to use is `Runtime.getRuntime().availableProcessors()`
- **elastic**: a scheduler that dynamically creates threads when needed, with no up limit. A thread is released after 60 non-working seconds.
- [ ] - `subscribeOn(...)` sets the scheduler for all the operations of your stream
- [ ] - `publishOn(...)` sets the scheduler for all the operations that follow this method call
- [ ] - `Flux` runs sequentially by default. To make a Flux parallel, there exists a `.parallel()` method in the class. Conversely, it is possible to turn a parallel flux into a sequential flux with the method `.sequential()`
- [ ] - the stream cannot be asynchronous if a publisher is synchronous and the stream is blocking if a publisher blocks
- [ ] - `Flux` and `Mono` objects model a suspendable, resumable chain of operations. It means the engine can "park" actions, and later schedule their execution on an available thread.
- [ ] - The **==best quick and simple overview==** about [Non-blocking I/O](https://medium.com/ing-blog/how-does-non-blocking-io-work-under-the-hood-6299d2953c74): 
- The main benefit of non-blocking IO is that we need less threads to handle the same amount of IO requests
- When data has returned from IO, the caller will be notified that the data is ready. This is generally done with a _callback_ function that has access to the returned data.
- Another important “optimization” is that a call to`kqueue(..)` or `epoll(..)` blocks if there is no ready data in the FDs of the interest list. This means that there are no unnecessary iterations in the event loop when there is no ready FD data.
- From kernel 5.1 Linux offers `[io_uring](https://github.com/axboe/liburing)`, which can even further optimize an event loop. It does so by minimizing expensive system calls and minimize copying of data.
- Applications that need to handle high event rates mostly use non-blocking IO models that are implemented with event loops. or best performance, the event loop is built using kernel APIs such as `kqueue`, `io_uring`, `epoll` and `IOCP`
- [ ] - `Future`(hot stream) is a pull based pub/sub and `Mono`(cold/hot stream) is push based pub/sub?? - [StackOverFlow](https://stackoverflow.com/questions/54238755/difference-between-a-future-and-a-mono#:~:text=Add%20a%20comment-,5,Producer%20and%20consumer%20can%20communicate%20in%202%20ways%3A%20synchronous%20and%20asynchronous,-.)
- [ ] - `Future` vs `CompletableFuture` vs `Mono`